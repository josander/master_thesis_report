\chapter{Discussion}
In this chapter, a discussion is held about the graph representation as well as the three studied cases. The chapter is concluded with a brief discussion about future work.

\section{Gh0st RAT Controllers}
% In discussion - what similarity measure was the most appropriate to use in our case?
Based on the results, we find that the simple local indices perform very well on the two data sets. The F$_1$ score seem to increase with the number of reference nodes which seems reasonable. 

It may be surprising that the classifier based on local similarity generates such good results. Two reasons are the density as well as the connectivity of the graph. The local similarity measures are based solely on the nearest neighbors implying that all of the RAT controllers must share one common neighbor with a known RAT controller from the start, i.e. a reference node. However, in the case where one (unclassified) RAT controller was positioned in the periphery of the network, away from the reference nodes, that would not have been properly classified. Hence, this particular method is highly dependent of the connectivity as well as a good distribution of the reference nodes in the graph. 

% Local performed better than quasi-local and global!

In XX \% of all the cases, three IP addresses annotated as \textit{Non-ghost}s were classified as \textit{Ghost}. There is reason to believe those IP addresses are falsely annotated and are in fact RAT controllers. (How can we prove it or make this claim stronger?)

\section{Malicious IP addresses}

% Skewed dataset
As previously mentioned, the dataset was extremely skewed. Thus a random classifier was implemented. 

% A lot of noise in the dataset
One reason for the low result may very well have to do with the noise in the dataset. It is hard to quantify the amount of noise present in the data, however it is only reasonable to believe it has a major impact on the results.

The idea was to include two more features, namely the betweenness centrality and the closeness centrality. The calculations were started in using Cypher in Neo4j. However, the large amount of data resulted in a very long runtime, and thus the calculations were ended after about 24 hours. Thus, the betweenness and closeness centrality might have contributed to better predictions but were excluded from the model since the calculations took too much time in relation to the time resources at hand. 

\section{Prediction of Future Cyber Attacks}
\input{chapters/cyberattacks_discussion.tex}

\section{Future Work}
This report has only covered a small part of interesting methods based on graph theory that might be of interest to apply to the cyber threat intelligence domain. Thus, we now present some interesting ideas that was stumbled upon without having the resources to try them out. 

In the Gh0st RAT controller case, structural equivalence was used for classification of nodes. However, there is another similarity called regular equivalence that takes the position of the node into consideration. Thus, two nodes are regularly equivalent if they are equally related to equivalent others. Although structural equivalence measure might have been enough for the RAT controller case, there are many different areas where regular similarity would suit better. However, the disadvantage of regular equivalence it that it implies an iterative or recursive nature since the similarity between the neighborhoods of the nodes has to be known before the similarity of the nodes themselves can be computed \cite{leicht2006}. Thus, the regular equivalence involves a higher complexity than many of the structural equivalence measures, howver it could lead to new insights. 

In this study, we have selected only a few features for our classifier. We have also limited our reseach to only account for a very small amount of all the information available in Recorded Future's database. Thus, a natural extension of this research may be to include other and more features in the classification model. Such studies could lead to more insights about Recorded Future's current classification system.

Another interesting idea is to mine the graph for often occurring sub-structures. This might be done with a more exploratory interest in mind. One algorithm for such a purpose is the AProximate Graph Mining (APGM) developed by \citet{Jia2011}, that looks for often occurring structures but accounts for noise and perturbations in the original data. This can be of high interest for Recorded Future because of the uncertain nature of the data, covered in \secref{dataset}.
